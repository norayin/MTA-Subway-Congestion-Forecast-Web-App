library(corrplot)
library(caret) 
library(AppliedPredictiveModeling)
library(stargazer)
library(ggmap)
library(tidyverse)
library(sf)
library(FNN)
library(data.table)
library(car)
library(spdep)
library(lubridate)
library(rgdal)
library(sp)
library(dplyr)

setwd("G:/Yinuo Yin/Study/Upenn/2018 Spring/LARP 745/MTA-Subway-Congestion/00Working")
load("G:/Yinuo Yin/Study/Upenn/2018 Spring/LARP 745/MTA-Subway-Congestion/00Working/MyData2.RData")

# Set up map theme
myTheme <- function() {
  theme_void() + 
    theme(
      text = element_text(size = 7),
      plot.title = element_text(size = 20, color = "#FEFFEF", hjust = 0.5, vjust = 0, face = "bold"), 
      plot.subtitle = element_text(size = 16, color = "#FEFFEF", hjust = 0.5, vjust = 0),
      axis.ticks = element_blank(),
      #panel.grid.major = element_line(colour = "gray95"),
      #panel.background = element_rect(fill = "gray95"),
      plot.background = element_rect(fill = "black", color="white"),
      panel.border = element_rect(colour = "gray95", fill=NA, size=2),
      legend.direction = "horizontal", 
      legend.position = "bottom",
      plot.margin = margin(0.5, 0.5, 0.5, 0.5, 'cm'),
      legend.key.height = unit(0.4, "cm"), legend.key.width = unit(0.8, "cm"),
      legend.title = element_text(size = 14, color = "#FEFFEF", hjust = 0.5, vjust = 0, face = "bold"),
      legend.text = element_text(size = 12, color = "#FEFFEF", hjust = 0.5, vjust = 0)
    )
}

# Import subway station entrance and exit data
subwayStation <- read.csv("NYC_Transit_Subway_Entrance_And_Exit_Data.csv")
MTA <- data.frame(Station = subwayStation$Station.Name,
                  Longitude = subwayStation$Station.Longitude,
                  Latitude = subwayStation$Station.Latitude)
MTA = MTA[!duplicated(MTA$Station),]

# Change all values to upper case text for join later
MTAStation <- mutate_all(MTA, funs(toupper)) %>%
  mutate(Longitude = as.numeric(MTA$Longitude),
         Latitude = as.numeric(MTA$Latitude))

# Modify station name for join later
MTAStation.modified <- MTAStation %>% 
  mutate(Station = gsub('TH', '', Station)) %>%
  mutate(Station = gsub('RD', '', Station)) %>%
  mutate(Station = gsub('ND', '', Station))

# Import turnstile data - filter by July and August 2017
turnstile <- read.csv("Turnstile_Usage_Data__2017.csv")

# Extract year and month for filtering, also day and weekday
time.date <- mdy(turnstile$Date)
turnstile.modified <-
  turnstile %>%
  mutate(Year = as.factor(year(time.date)), 
         Month = as.factor(month(time.date)), 
         Day = as.factor(day(time.date)), 
         Weekday = as.factor(wday(time.date)),
         Station = as.factor(Station))

# Filter by year
turnstile2017 <- filter(turnstile.modified, Year == 2017)
# Filter by month
turnstileJulAug <- filter(turnstile2017, Month == 7 | Month == 8)

# Add hour to the data frame
time <- hms(turnstileJulAug$Time)
turnstileJulAug <- turnstileJulAug %>%
  mutate(Hour = as.factor(lubridate::hour(time)))

# DATA WRANGLING #
# A "serial number" named "serial" is created a concatenated column in order to create a unique identifier for each turnstile unit.
turnstileJulAug$serial<-paste(turnstileJulAug$C.A,turnstileJulAug$Unit,turnstileJulAug$SCP,sep='')

# Each unit is sorted by serial (newly created), date, time
turnstileJulAug<-arrange(turnstileJulAug,serial,Date,Time)

# Some record time in 1-5-9-13-17-21, some in 0-4-8-12-16-20
# Don't need other hour's data
turnstileJulAug.filter <- filter(turnstileJulAug, Hour != 2 & Hour != 3 & Hour != 6 & Hour != 7 & Hour != 10 & Hour != 11 & Hour != 14 & 
                                   Hour != 15 & Hour != 18 & Hour != 19 & Hour != 22 & Hour != 23)

# The fields ENTRIES and EXITS do not show the entries and exits.  
# These are the actual numbers on the turnstile counters.  
# To get actual entries and exits, the difference between the counter at t and t-1 must be taken.  
netcalc <- turnstileJulAug.filter %>%
  # group by is used because we need the operation performed within 
  # each the observations for each individual turnstile unit.
  group_by(serial) %>%  
  mutate(Net_Entries= Entries - lag(Entries))

netcalc <- netcalc %>%
  # group by is used because we need the operation performed within 
  # each the observations for each individual turnstile unit.
  group_by(serial) %>%  
  mutate(Net_Exits= Exits - lag(Exits))

# DATA CLEANING #
# Taking a closer look at the units with negative entries, negative exits, or NA 
# (but we already know NA is generated by the offset function above for the entry of each turnstile unit).
suspect_data <- filter(netcalc, Net_Entries<0 | Net_Exits<0 | is.na(Net_Exits) | is.na(Net_Entries))

suspect_data_summary <- suspect_data %>%
  group_by(serial) %>%
  summarise(error_count = n())

# The summary of the suspect data shows that on average, the machines having issues show up about 5 times.  
# However, the summary shows that there is one machine that is have 382 error occurences.  
# That should be checked out more closely as it is an indicator that something is wrong and maybe all 
# the data from that turnstile should be removed.
summary(suspect_data_summary)

# Actually, there are quite a few turnstiles that have many issues.  
bad_unit <- arrange(suspect_data_summary,desc(error_count))

# Delete all units with error count > 100 times
bad_unit <- filter(bad_unit, error_count > 100) %>%
  mutate(bad = 1) %>%
  select(-error_count)
netcalc1 <- left_join(netcalc, bad_unit)
netcalc1[is.na(netcalc1)] <- 0

filtered_unit <- filter(netcalc1, bad == 0) %>%
  select(-bad)

# Match stations
# The station names are very messy - had to write to csv to clean the data
# Get list of stations in turnstile data
turnstileStation <- data.frame(Station = filtered_unit$Station,
                               Division = filtered_unit$Division)
turnstileStation = turnstileStation[!duplicated(turnstileStation$Station),]

# write.csv(MTAStation.modified, file="station.csv")
# write.csv(turnstileStation, file="turnstileStation.csv")

# After modification, write the station file back into R
MTAStation.modified2 <- read.csv("station.csv")

# Make sure the station has turnstile data in both July and August
MTAStation2 <- MTAStation.modified2 %>%
  filter(Station %in% turnstileStation$Station)

# Total stations in consideration: 312

#******************************* Map 1: subway locations ************************#
# Plot subway station on NYC map
# Set up basemap
baseMap <- get_map(location = c(lon = -73.9402338, lat = 40.7422241),
                   zoom = 11, 
                   maptype= 'toner-lite')
# Plot
ggmap(baseMap) + 
  geom_point(data= MTAStation2,
             aes(x = Longitude, y = Latitude),
             colour = "orange",
             size = 2) +
  labs(title="MTA SUBWAY STATIONS",
       subtitle = "New York City, NY\n ") +
  myTheme()
#********************************************************************************#

# Take a look at precedents
precedents <- read.csv("turnstile_weather_v2.csv")

# change 4AV-9 ST to 4 AV-9 ST
# change BEVERLEY ROAD to BEVERLY RD
# change HUNTS POINT AV to HUNTERS PT AV

# Finally ready to join
turnstileJoinStation <- left_join(filtered_unit, MTAStation2)

turnstileJoinStation$Station <- as.factor(turnstileJoinStation$Station)
turnstileJoinStation$Month <- as.factor(turnstileJoinStation$Month)
turnstileJoinStation$Day <- as.factor(turnstileJoinStation$Day)
turnstileJoinStation$Hour <- as.factor(turnstileJoinStation$Hour)

# Some stations have no lat and lon, remove them
MyData <- na.omit(turnstileJoinStation, cols=c("Longitude", "Latitude"))

# 312 stations * 6 rows of turnstile data update per day * 31 day * 2 months = 116,064 rows of data
# Recall that some turnstiles record time in 1-5-9-13-17-21, others in 0-4-8-12-16-20

# Aggregate data
MyData$Entries <- as.numeric(MyData$Entries)
MyData$Exits <- as.numeric(MyData$Exits)

MyData_Aggregate <-
  MyData %>%
  group_by(Station, Date, Hour) %>%
  summarise(NetEntries = sum(Net_Entries),
            NetExits = sum(Net_Exits)) %>%
  as.data.frame()

# Count how many rows of data each sation has
# Ideally, each station should have 6 * 31 * 2 = 372 rows of data
N_Station <- MyData_Aggregate %>%
  group_by(Station) %>%
  summarise(count=n()) %>%
  arrange(count)

# How many stations have 372 rows of data? Only 110
ideal_station <- filter(N_Station, count == 372)

# Merge data frames to get lat and lon
FinalAggregate <- left_join(MyData_Aggregate, MTAStation2)
# Should not have any NAs, but just to make sure 
FinalAggregate <- na.omit(FinalAggregate, cols=c("Longitude", "Latitude"))

# For the sake of the regression later, I may have to decide to go with 0-4-8-12-16-20 or 1-5-9-13-17-21
# Find which stations have data at 0-4-8-12-16-20
data_group1 <- filter(FinalAggregate, Hour == 0|Hour == 4|Hour == 8|Hour == 12|Hour == 16|Hour == 20)
station_group1 <- data_group1 %>%
  group_by(Station) %>%
  summarise(count=n()) %>%
  mutate(count = as.numeric(count)) %>%
  arrange(count)
ideal_station1 <- filter(station_group1, count >= 372) # 159
# Find which stations have data at 1-5-9-13-17-21
data_group2 <- filter(FinalAggregate, Hour == 1|Hour == 5|Hour == 9|Hour == 13|Hour == 17|Hour == 21)
station_group2 <- data_group2 %>%
  group_by(Station) %>%
  summarise(count=n()) %>%
  mutate(count = as.numeric(count)) %>%
  arrange(count)
ideal_station2 <- filter(station_group2, count >= 372) # 134

# Well, group 1 seems to have more stations with all 6 hours of data

########################## Now, use the FinalAggregate df to add other variables ############################

### Variable 1: weather, including precipitation and temperature ###
# Weather underground API key: 665e26a4d6244eee
# Obtain data from https://www.kaggle.com/selfishgene/historical-hourly-weather-data/version/2#_=_
# Import raw weather data downloaded from the site
humidity <- read.csv("weather_raw_data/humidity.csv")
pressure <- read.csv("weather_raw_data/pressure.csv")
temperature <- read.csv("weather_raw_data/temperature.csv")
weather_description <- read.csv("weather_raw_data/weather_description.csv")
wind_speed <- read.csv("weather_raw_data/wind_speed.csv")
wind_direction <- read.csv("weather_raw_data/wind_direction.csv")

# Only need New York data
humidityNY <- data.frame(TIME = humidity$datetime,
                         HUMIDITY = humidity$New.York)
pressureNY <- data.frame(TIME = pressure$datetime,
                         PRESSURE = pressure$New.York)
temperatureNY <- data.frame(TIME = temperature$datetime,
                            TEMP = temperature$New.York)
weather_descriptionNY <- data.frame(TIME = weather_description$datetime,
                                    WEATHER = weather_description$New.York)
wind_speedNY <- data.frame(TIME = wind_speed$datetime,
                           WIND_SPEED = wind_speed$New.York)
wind_directionNY <- data.frame(TIME = wind_direction$datetime,
                               WIND_DIR = wind_direction$New.York)
# Combine all weather data
weather.data <- data.frame()
weather.data <- left_join(temperatureNY, humidityNY)
weather.data <- left_join(weather.data, pressureNY)
weather.data <- left_join(weather.data, wind_speedNY)
weather.data <- left_join(weather.data, wind_directionNY)
weather.data <- left_join(weather.data, weather_descriptionNY)

# Filter weather data by year and month, recall that we only need July and August 2017's data
# First separate date and hour, and modified the date "-" to "/"
weather.data <- weather.data %>% 
  mutate(DATE_TIME = weather.data$TIME) %>%
  separate(col = TIME, into = c('DATE', 'TIME'), sep = ' ') %>%
  mutate(DATE = gsub('-', '/', DATE))

weather.data$DATE <- as.factor(weather.data$DATE)
weather.data$TIME <- as.factor(weather.data$TIME)

weather.time <- ymd_hms(weather.data$DATE_TIME)

weather.data <-
  weather.data %>%
  mutate(Year = as.factor(year(weather.time)), 
         Month = as.factor(month(weather.time)), 
         Day = as.factor(day(weather.time)),
         Hour = as.factor(hour(weather.time)))

weather.data2017 <- filter(weather.data, Year == 2017)
weather.data78 <- filter(weather.data2017, Month == 7 | Month == 8)

# Add month, day columns for FinalAggregate
time2 <- mdy(FinalAggregate$Date)
FinalAggregate <- FinalAggregate %>%
  mutate(Month = as.factor(month(time2)), 
         Day = as.factor(day(time2)))

# Join weather data to FinalAggregate
joinweather <- left_join(FinalAggregate, weather.data78, by = c('Month'='Month', 'Day'='Day', 'Hour' = 'Hour')) %>%
  select(-DATE, -TIME, -DATE_TIME, -Year)

# Note: temperature is in Kelvin, 
# The relationship between Kelvin and Celsius is [K] - 273.15 = [C]
# Convert temperature to celcius for easier interpretation later
joinweather$TEMP_C = joinweather$TEMP - 273.15

### Variable 2: proximity variables ###
# distance to bus stops, schools, CBD, parks, nearby subway stations

MTAStation3 <- st_as_sf(MTAStation2, coords = c("Longitude", "Latitude"), crs = 4326)
data <- MTAStation2

# 1: distance to public schools
school <- st_read("Public_Schools_Points_2011-2012A.shp")

school <- school %>%
  select(geometry) %>%
  st_transform(4326) %>%
  mutate(landUse = "school")
Station <- MTAStation3 %>%
  select(geometry) %>%
  st_transform(4326) %>%
  mutate(landUse = "Station")

allPlaces <- rbind(school, Station)
allPlaces <- cbind(as.data.frame(st_coordinates(allPlaces)), data.frame(allPlaces))

schoolXY <-
  allPlaces %>%
  filter(landUse == "school") %>%
  select(X,Y) %>%
  as.matrix() 
StationXY <-
  allPlaces %>%
  filter(landUse == "Station") %>%
  select(X,Y) %>%
  as.matrix()   

nn = get.knnx(schoolXY,StationXY,k=5)

data <-
  as.data.frame(nn$nn.dist) %>%
  rownames_to_column(var = "Station") %>%
  gather(school, school_Distance, V1:V5) %>%
  arrange(as.numeric(Station)) %>%
  group_by(Station) %>%
  summarize(d_school = mean(school_Distance)) %>%
  arrange(as.numeric(Station)) %>% 
  select(-Station) %>%
  bind_cols(data)

# 2: distance to bus stops
# Data obtained from https://www.baruch.cuny.edu/confluence/display/geoportal/NYC+Mass+Transit+Spatial+Layers
# and https://geo.nyu.edu/catalog/nyu_2451_34693 
busstop <- st_read("stops_mn_bus_may2016.shp")

busstop <- busstop %>%
  select(geometry) %>%
  st_transform(4326) %>%
  mutate(landUse = "busstop")

allPlaces <- rbind(busstop, Station)
allPlaces <- cbind(as.data.frame(st_coordinates(allPlaces)), data.frame(allPlaces))

busstopXY <-
  allPlaces %>%
  filter(landUse == "busstop") %>%
  select(X,Y) %>%
  as.matrix() 

nn = get.knnx(busstopXY,StationXY,k=5)

data <-
  as.data.frame(nn$nn.dist) %>%
  rownames_to_column(var = "Station") %>%
  gather(busstop, busstop_Distance, V1:V5) %>%
  arrange(as.numeric(Station)) %>%
  group_by(Station) %>%
  summarize(d_busstop = mean(busstop_Distance)) %>%
  arrange(as.numeric(Station)) %>% 
  select(-Station) %>%
  bind_cols(data)

# 3: distance to cbd
# I obtained the centroid of Manhattan in ArcGIS and export centroid as a shapefile
cbd <- read.csv("cbd_centroid.csv")
cbd <- filter(cbd, boro_name == "Manhattan")
cbd <- st_as_sf(cbd, coords = c("X", "Y"), crs = 4326)

cbd <- cbd %>%
  select(geometry) %>%
  st_transform(4326) %>%
  mutate(landUse = "cbd")

allPlaces <- rbind(cbd, Station)
allPlaces <- cbind(as.data.frame(st_coordinates(allPlaces)), data.frame(allPlaces))

cbdXY <-
  allPlaces %>%
  filter(landUse == "cbd") %>%
  select(X,Y) %>%
  as.matrix() 

nn = get.knnx(cbdXY,StationXY,k=1)

data <-
  as.data.frame(nn$nn.dist) %>%
  rownames_to_column(var = "Station") %>%
  gather(cbd, cbd_Distance, V1) %>%
  arrange(as.numeric(Station)) %>%
  group_by(Station) %>%
  summarize(d_cbd = mean(cbd_Distance)) %>%
  arrange(as.numeric(Station)) %>% 
  select(-Station) %>%
  bind_cols(data)

# 4: distance to parks
parks <- read.csv("large_park.csv")
parks <- st_as_sf(parks, coords = c("Longitude", "Latitude"), crs = 4326)

parks <- parks %>%
  select(geometry) %>%
  st_transform(4326) %>%
  mutate(landUse = "parks")

allPlaces <- rbind(parks, Station)
allPlaces <- cbind(as.data.frame(st_coordinates(allPlaces)), data.frame(allPlaces))

parksXY <-
  allPlaces %>%
  filter(landUse == "parks") %>%
  select(X,Y) %>%
  as.matrix() 

nn = get.knnx(parksXY,StationXY,k=5)

data <-
  as.data.frame(nn$nn.dist) %>%
  rownames_to_column(var = "Station") %>%
  gather(parks, parks_Distance, V1:V5) %>%
  arrange(as.numeric(Station)) %>%
  group_by(Station) %>%
  summarize(d_parks = mean(parks_Distance)) %>%
  arrange(as.numeric(Station)) %>% 
  select(-Station) %>%
  bind_cols(data)

# 5: distance to nearby subway stations
subway <- MTAStation3 %>%
  select(geometry) %>%
  st_transform(4326) %>%
  mutate(landUse = "subway")

allPlaces <- rbind(subway, Station)
allPlaces <- cbind(as.data.frame(st_coordinates(allPlaces)), data.frame(allPlaces))

subwayXY <-
  allPlaces %>%
  filter(landUse == "subway") %>%
  select(X,Y) %>%
  as.matrix() 

nn = get.knnx(subwayXY,StationXY,k=5)

data <-
  as.data.frame(nn$nn.dist) %>%
  rownames_to_column(var = "Station") %>%
  gather(subway, subway_Distance, V1:V5) %>%
  arrange(as.numeric(Station)) %>%
  group_by(Station) %>%
  summarize(d_subway = mean(subway_Distance)) %>%
  arrange(as.numeric(Station)) %>% 
  select(-Station) %>%
  bind_cols(data)

# Check facilities dataset in NYC to see if there are more proximity variables that can be added
facility <- st_read("NYCfacility.shp")
## levels(facility$factype)

# 6 more proximity factors
# Colleges or universities
college <- filter(facility, facsubgrp == "Colleges or Universities")
# Hospitals and clinics
hospital <- filter(facility, facsubgrp == "Hospitals and Clinics")
# Offices
office <- filter(facility, facsubgrp == "Offices")
# Parking lots
parkinglot <- filter(facility, facsubgrp == "Parking Lots and Garages")
# Recreation and Waterfront Sites
recreation <- filter(facility, facsubgrp == "Recreation and Waterfront Sites")
# Streetscapes, Plazas, and Malls
plazamalls <- filter(facility, facsubgrp == "Streetscapes, Plazas, and Malls")

# Now ready to prepare more proxity factors
# College
location <- college
location <- location %>%
  select(geometry) %>%
  st_transform(4326) %>%
  mutate(landUse = "location")
allPlaces <- rbind(location, Station)
allPlaces <- cbind(as.data.frame(st_coordinates(allPlaces)), data.frame(allPlaces))
locationXY <-
  allPlaces %>%
  filter(landUse == "location") %>%
  select(X,Y) %>%
  as.matrix() 
nn = get.knnx(locationXY,StationXY,k=5)
data <-
  as.data.frame(nn$nn.dist) %>%
  rownames_to_column(var = "Station") %>%
  gather(location, location_Distance, V1:V5) %>%
  arrange(as.numeric(Station)) %>%
  group_by(Station) %>%
  summarize(d_college = mean(location_Distance)) %>%
  arrange(as.numeric(Station)) %>% 
  select(-Station) %>%
  bind_cols(data)

# Hospital
location <- hospital
location <- location %>%
  select(geometry) %>%
  st_transform(4326) %>%
  mutate(landUse = "location")
allPlaces <- rbind(location, Station)
allPlaces <- cbind(as.data.frame(st_coordinates(allPlaces)), data.frame(allPlaces))
locationXY <-
  allPlaces %>%
  filter(landUse == "location") %>%
  select(X,Y) %>%
  as.matrix() 
nn = get.knnx(locationXY,StationXY,k=5)
data <-
  as.data.frame(nn$nn.dist) %>%
  rownames_to_column(var = "Station") %>%
  gather(location, location_Distance, V1:V5) %>%
  arrange(as.numeric(Station)) %>%
  group_by(Station) %>%
  summarize(d_hospital = mean(location_Distance)) %>%
  arrange(as.numeric(Station)) %>% 
  select(-Station) %>%
  bind_cols(data)

# Offices
location <- office
location <- location %>%
  select(geometry) %>%
  st_transform(4326) %>%
  mutate(landUse = "location")
allPlaces <- rbind(location, Station)
allPlaces <- cbind(as.data.frame(st_coordinates(allPlaces)), data.frame(allPlaces))
locationXY <-
  allPlaces %>%
  filter(landUse == "location") %>%
  select(X,Y) %>%
  as.matrix() 
nn = get.knnx(locationXY,StationXY,k=5)
data <-
  as.data.frame(nn$nn.dist) %>%
  rownames_to_column(var = "Station") %>%
  gather(location, location_Distance, V1:V5) %>%
  arrange(as.numeric(Station)) %>%
  group_by(Station) %>%
  summarize(d_office = mean(location_Distance)) %>%
  arrange(as.numeric(Station)) %>% 
  select(-Station) %>%
  bind_cols(data)

# Parking lots
location <- parkinglot
location <- location %>%
  select(geometry) %>%
  st_transform(4326) %>%
  mutate(landUse = "location")
allPlaces <- rbind(location, Station)
allPlaces <- cbind(as.data.frame(st_coordinates(allPlaces)), data.frame(allPlaces))
locationXY <-
  allPlaces %>%
  filter(landUse == "location") %>%
  select(X,Y) %>%
  as.matrix() 
nn = get.knnx(locationXY,StationXY,k=5)
data <-
  as.data.frame(nn$nn.dist) %>%
  rownames_to_column(var = "Station") %>%
  gather(location, location_Distance, V1:V5) %>%
  arrange(as.numeric(Station)) %>%
  group_by(Station) %>%
  summarize(d_parkinglot = mean(location_Distance)) %>%
  arrange(as.numeric(Station)) %>% 
  select(-Station) %>%
  bind_cols(data)

# Recreation and Waterfront Sites
location <- recreation
location <- location %>%
  select(geometry) %>%
  st_transform(4326) %>%
  mutate(landUse = "location")
allPlaces <- rbind(location, Station)
allPlaces <- cbind(as.data.frame(st_coordinates(allPlaces)), data.frame(allPlaces))
locationXY <-
  allPlaces %>%
  filter(landUse == "location") %>%
  select(X,Y) %>%
  as.matrix() 
nn = get.knnx(locationXY,StationXY,k=5)
data <-
  as.data.frame(nn$nn.dist) %>%
  rownames_to_column(var = "Station") %>%
  gather(location, location_Distance, V1:V5) %>%
  arrange(as.numeric(Station)) %>%
  group_by(Station) %>%
  summarize(d_recreation = mean(location_Distance)) %>%
  arrange(as.numeric(Station)) %>% 
  select(-Station) %>%
  bind_cols(data)

# Streetscapes, Plazas, and Malls
location <- plazamalls
location <- location %>%
  select(geometry) %>%
  st_transform(4326) %>%
  mutate(landUse = "location")
allPlaces <- rbind(location, Station)
allPlaces <- cbind(as.data.frame(st_coordinates(allPlaces)), data.frame(allPlaces))
locationXY <-
  allPlaces %>%
  filter(landUse == "location") %>%
  select(X,Y) %>%
  as.matrix() 
nn = get.knnx(locationXY,StationXY,k=5)
data <-
  as.data.frame(nn$nn.dist) %>%
  rownames_to_column(var = "Station") %>%
  gather(location, location_Distance, V1:V5) %>%
  arrange(as.numeric(Station)) %>%
  group_by(Station) %>%
  summarize(d_plazamalls = mean(location_Distance)) %>%
  arrange(as.numeric(Station)) %>% 
  select(-Station) %>%
  bind_cols(data)

# Now done with proximity factors (in total 11)

### Variable 3: census variables ###
census <- st_read("NYCcensus.shp")
census <- st_transform(census, st_crs(MTAStation3))

data_sf <- st_as_sf(data, coords = c("Longitude", "Latitude"), crs = 4326)

joincensus <-st_join(data_sf,census)

# Deal with NAs
joincensus[rowSums(is.na(joincensus))!=0,]
# The following stations do not get a census match
# 34 ST-HERALD SQ - 4979
# BROAD CHANNEL - 3693
# GRAND-NEWTOWN - 6410
# HOWARD BCH JFK - 3713
# JKSN HT-ROOSVLT - 6326
# ROOSEVELT ISLND - 5308
NAs <- filter(joincensus, Station == "34 ST-HERALD SQ" |Station == "BROAD CHANNEL" |Station == "GRAND-NEWTOWN" |
                Station == "HOWARD BCH JFK" |Station == "JKSN HT-ROOSVLT" |Station == "ROOSEVELT ISLND" )
## st_write(NAs, "NAs.shp")

# Visualize these station in ArcGIS and select the closest block group data as the census data for these 6 grps
censusforNAs <- filter(census, ENRICH_FID == 4979 |ENRICH_FID == 3693 |ENRICH_FID == 6410 |
                         ENRICH_FID == 3713 |ENRICH_FID == 6326 |ENRICH_FID == 5308)
censusforNAs <- as.data.frame(censusforNAs)
censusforNAs <- censusforNAs[,c(1:26)]

NAs$ENRICH_FID[NAs$Station=="34 ST-HERALD SQ"] <- 4979
NAs$ENRICH_FID[NAs$Station=="BROAD CHANNEL"] <- 3693
NAs$ENRICH_FID[NAs$Station=="GRAND-NEWTOWN"] <- 6410
NAs$ENRICH_FID[NAs$Station=="HOWARD BCH JFK"] <- 3713
NAs$ENRICH_FID[NAs$Station=="JKSN HT-ROOSVLT"] <- 6326
NAs$ENRICH_FID[NAs$Station=="ROOSEVELT ISLND"] <- 5308
NAs <- NAs[,c(1:12,20)]
NAs <- as.data.frame(NAs)

joincensus.NAs <- left_join(NAs, censusforNAs, by="ENRICH_FID")
joincensus.NAs <- subset(joincensus.NAs, select=c(1:13,15:39,14))
joincensus.NAs <- as.data.frame(joincensus.NAs)
joincensus <- as.data.frame(joincensus)

joincensus <- subset(joincensus, !is.na(HasData))
joincensus <- rbind(joincensus, joincensus.NAs)

joincensus <- joincensus[,c(1:12,23:39)]

### Variable 4: time lag ###
# Get previous hour time lag value
jointimelag <- joinweather %>%
  mutate(Hour = as.numeric(joinweather$Hour)) %>%
  arrange(Station, Date, Hour)

timelag <- lag(jointimelag$Hour, k=1)
lag_NEntries <- lag(jointimelag$NetEntries, k=1)
lag_NExits <- lag(jointimelag$NetExits, k=1)
jointimelag <- data.frame(cbind(jointimelag, timelag, lag_NEntries, lag_NExits))
jointimelag <- subset(jointimelag, select = -timelag)

# Now deal with 0 and NAs in Entries and Exits fields
# We just need the last two rows of net entries and exits data in June 2017
turnstileJune <- filter(turnstile.modified, Month == 6)
turnstileJune30 <- filter(turnstileJune, Day == 30) # 0 results
# Work around: may have to turn NA to 0
jointimelag <- replace(jointimelag, is.na(jointimelag), 0)

### Variable 5: day of the week ###
timevars <- jointimelag
time.vars <- mdy(timevars$Date)
timevars <- timevars %>%
  mutate(Weekday = wday(time.vars))

### Variable 6: rush hour or not ###
# "Peak Fares are charged during business rush hours, on any weekday train scheduled 
# to arrive in NYC terminals between 6 and 10 AM or depart NYC terminals between 4 and 8 PM."
# 0 1 4 5 8 9 12 13 16 17 20 21
# Rush hour: 8,9,16,17,20
timevars$Rush_Hour <- "0"
timevars <- timevars %>%
  mutate(Rush_Hour = ifelse(timevars$Hour==8|timevars$Hour==9|timevars$Hour==16|
                              timevars$Hour==17|timevars$Hour==20, "1", "0"))

### Variable 7: national holiday or event ###
# Only July has a federal holiday: Independence day
timevars <- timevars %>%
  mutate(Holiday = ifelse(timevars$Date=="07/04/2017", "1", "0")) 

# Get event calendar in July and Aug 2017
event_holiday <- read.csv("NYC_Permitted_Event_Information_-_Historical.csv")
time.event = mdy_hms(event_holiday$Start.Date.Time)
time.event.end = mdy_hms(event_holiday$End.Date.Time)
event_holiday <- event_holiday %>%
  mutate(Year = year(time.event),
         Month = month(time.event),
         Day = day(time.event),
         Hour = hour(time.event),
         E_Year = year(time.event.end),
         E_Month = month(time.event.end),
         E_Day = day(time.event.end),
         E_Hour = hour(time.event.end))

# Count number of event per hour according to start time
event_holiday2017 <- filter(event_holiday, Year == 2017)
event_holiday78 <- filter(event_holiday2017 , Month == 7|Month == 8)

count_event <- event_holiday78 %>%
  group_by(Month, Day, Hour) %>%
  summarise(Event_Count = n())

count_event$Month <- as.character(count_event$Month)
count_event$Day <- as.character(count_event$Day)
count_event$Hour <- as.character(count_event$Hour)
timevars$Hour <- as.character(timevars$Hour)

joinevent <- left_join(timevars, count_event, by=c("Month","Day","Hour"))
joinevent$Event_Count <- replace(joinevent$Event_Count, is.na(joinevent$Event_Count), 0)

# Count number of event per hour according to end time
event_holiday2017 <- filter(event_holiday, E_Year == 2017)
event_holiday78 <- filter(event_holiday2017 , E_Month == 7|E_Month == 8)

count_event <- event_holiday78 %>%
  group_by(E_Month, E_Day, E_Hour) %>%
  summarise(Event_Count2 = n())

count_event$Month <- as.character(count_event$E_Month)
count_event$Day <- as.character(count_event$E_Day)
count_event$Hour <- as.character(count_event$E_Hour)
count_event <- count_event[,c(4:7)]

joinevent <- left_join(joinevent, count_event, by=c("Month","Day","Hour"))
joinevent$Event_Count2 <- replace(joinevent$Event_Count2, is.na(joinevent$Event_Count2), 0)

### Variable 8: bike trips ###
# Data obtained from https://www.citibikenyc.com/system-data
addbiketrips <- joinevent

biketrip7 <- read.csv("JC-201707-citibike-tripdata.csv")
biketrip8 <- read.csv("JC-201708 citibike-tripdata.csv")
biketrips <- rbind(biketrip7,biketrip8)

time.bike <- ymd_hms(biketrips$starttime)
biketrips <- biketrips %>%
  mutate(Month = as.character(month(time.bike)),
         Day = as.character(day(time.bike)),
         Hour = as.character(hour(time.bike)))

count_biketrips <- biketrips %>%
  group_by(Month, Day, Hour) %>%
  summarise(BikeTrips = n())

addbiketrips <- left_join(addbiketrips, count_biketrips, by=c("Month","Day","Hour"))

### Variable 9: taxi trips ###
# Data obtained from https://data.cityofnewyork.us/Transportation/2017-Green-Taxi-Trip-Data/5gj9-2kzx
# and https://data.cityofnewyork.us/Transportation/2017-Yellow-Taxi-Trip-Data/biws-g3hs
addtaxitrips <- addbiketrips

# Green taxi
taxi_g <- read.csv("2017_Green_Taxi_Trip_Data.csv")

taxi_g <- taxi_g %>%
  mutate(Start_Time = taxi_g$lpep_pickup_datetime)

time.taxi <- mdy_hms(taxi_g$Start_Time)
taxitrips <- taxi_g %>%
  mutate(Year = as.character(year(time.taxi)),
         Month = as.character(month(time.taxi)),
         Day = as.character(day(time.taxi)),
         Hour = as.character(hour(time.taxi)))

taxitrips.filter <- filter(taxitrips, Year == 2017)
taxitrips.filter <- filter(taxitrips.filter, Month == 7|Month == 8)

count_taxitrips <- taxitrips.filter %>%
  group_by(Month, Day, Hour) %>%
  summarise(TaxiTrips = n())

addtaxitrips <- left_join(addtaxitrips, count_taxitrips, by=c("Month","Day","Hour"))

# Yellow taxi (already filtered by July and Aug 2017)
addtaxitrips2 <- addtaxitrips
taxi_y <- read.csv("2017_Yellow_Taxi_Trip_Data.csv")

time.taxi2 <- mdy_hms(taxi_y$tpep_pickup_datetime)
taxitrips2 <- taxi_y %>%
  mutate(Year = as.character(year(time.taxi2)),
         Month = as.character(month(time.taxi2)),
         Day = as.character(day(time.taxi2)),
         Hour = as.character(hour(time.taxi2)))

taxitrips.filter2 <- taxitrips2

count_taxitrips2 <- taxitrips.filter2 %>%
  group_by(Month, Day, Hour) %>%
  summarise(TaxiTrips2 = n())

addtaxitrips2 <- left_join(addtaxitrips2, count_taxitrips2, by=c("Month","Day","Hour"))

# Finally, ready to combine all variables
vars <- left_join(addtaxitrips2, joincensus, by = "Station")
names(vars)

write.csv(vars, file = "variables.csv")

############################## HAVE NOT RUN ################################
# Problems found:
# many 0s and negative numbers for dependent variable
# many NAs of bike trips


############################## DO NOT RUN TO BE DELETE LATER ################################

##data <- subset(data, select = -d_parkinglot2)

# Import subway station data
MTAStation2 <- read.csv("MTA_SUBWAY_STATION.csv")
# MTAStation <- st_read("SubwayStations.shp")
MTAStation2 <- MTAStation2 %>% 
  mutate(the_geom = gsub('[()°]', '', the_geom )) %>% 
  separate(col = the_geom, into = c('Type', 'Longitude', 'Latitude'), sep = ' ')
MTAStation2 <- MTAStation2 %>%
  mutate(Longitude = as.numeric(MTAStation2$Longitude),
         Latitude = as.numeric(MTAStation2$Latitude))